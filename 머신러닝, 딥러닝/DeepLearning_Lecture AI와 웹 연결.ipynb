{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Pwe8VXyK9QAj"
      },
      "outputs": [],
      "source": [
        "# torch 는 딥러닝을 구성하기 편하도록 페이스북에서 만든 딥러닝 라이브러리. 텐서플로우랑 똑같은 딥러닝 라이브러리.\n",
        "import torch\n",
        "\n",
        "# 신경망 구축을 쉽게 해주는 함수.\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 확인  GPU가 없으면 cpu로 연산 , GPU가 있으면 GPU로 연산하겠다는 준비  따라서 device 는 cpu나 gpu 문자열로 바뀐다.\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LO8xipy4AKq_",
        "outputId": "bbf4ab7b-20ca-4612-d8c9-a4ebb8e147be"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4명의 데이터가 있는데, 1명당 2개의 컬럼을 가지고 있다. 그리고 그걸 2차원 리스트로 4명의 데이터를 선언 후 \n",
        "#토치가 알아 먹을 수 있는 텐서타입으로 바꾼다. 이때 텐서타입은 float \n",
        "# to(device)는 모델이 gpu에서 연산될 것이기 때문에 to(cuda)를 함으로써 데이터를 gpu에 얹혀 놓는다.\n",
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"
      ],
      "metadata": {
        "id": "4bc_Xp_EAKok"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "          nn.Linear(2, 10, bias=True), # input_layer = 2, hidden_layer1 = 10\n",
        "          nn.Sigmoid(),\n",
        "           #batch normalization\n",
        "          nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10\n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3 = 10\n",
        "          nn.Sigmoid(),\n",
        "          nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\n",
        "          nn.Sigmoid()\n",
        "          ).to(device)"
      ],
      "metadata": {
        "id": "kumbEtW9AKla"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.MSELoss().to(device) #Mean Square Error\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)  # 옵티마이저인 Stochestic Gradient Descent 를 쓸거다. 업데이트 대상은 model 객체가 가지고 있는\n",
        "                                                          # W 들을 대상으로 업데이트를 할 것이고, learning rate 는 0.001로 설정할 것이다."
      ],
      "metadata": {
        "id": "37NqtMcuAKeq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(50): # 50번 학습할거다.\n",
        "  optimizer.zero_grad() # 옵티마이저의 기울기를 매번 초기화 해서 계산해야 하기 때문에 초기화 하는 함수를 선언\n",
        "  # forward 연산\n",
        "  hypothesis = model(X) # 모델에 데이터를 넣고, propagation을 진행한 후 , 최종 아웃풋을 hypothesis 에 담는다.\n",
        "\n",
        "  #비율 함수\n",
        "  cost = criterion(hypothesis, Y) # 예측값과 정답값 사이의 Mean Square Loss 를 구함\n",
        "  cost.backward() # backpropagation이 아니다. 이름에 낚이지 말자. 이 부분은 기울기를 구하는 함수다\n",
        "  optimizer.step() # 여기서 비로소 backpropagation을 실행하여 모델의 미ㅗ든 w들을 업데이트 한다\n",
        "\n",
        "  # 5의 배수에 해당되는 에포크마다 비용을 출력력\n",
        "  if epoch % 5 == 0:\n",
        "        print(\"에폭:\", epoch, cost.item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swtk756DEfN1",
        "outputId": "1a916b3c-d5fd-473d-de6d-562cad78400f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에폭: 0 0.2604835629463196\n",
            "에폭: 5 0.26044291257858276\n",
            "에폭: 10 0.2604024410247803\n",
            "에폭: 15 0.26036202907562256\n",
            "에폭: 20 0.26032179594039917\n",
            "에폭: 25 0.2602817416191101\n",
            "에폭: 30 0.2602418065071106\n",
            "에폭: 35 0.260202020406723\n",
            "에폭: 40 0.2601623833179474\n",
            "에폭: 45 0.2601228952407837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_2 = torch.FloatTensor([[0, 0], [0, 1]]).to(device)\n",
        "hypothesis = model(X_2)   # fitting 된 모델에 데이터를 넣어서 inference 하는 부분\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y7VF3JZCGEK3",
        "outputId": "1bf05e55-aa8b-4e6a-eb3b-f7222e0cf1c3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3997],\n",
            "        [0.4000]], device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **minibatch DNN**"
      ],
      "metadata": {
        "id": "UG-RU31pH097"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
        "from torch.utils.data import DataLoader # 데이터로더"
      ],
      "metadata": {
        "id": "sORO8AnLHvfO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 확인\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "VLJJMCS0HyND"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5명의 데이터, 각 데이터는 3개의 칼럼(피처)를 갖는다.\n",
        "x_train = torch.FloatTensor([[73, 80, 75],\n",
        "                             [93, 88, 93],\n",
        "                             [89, 91, 90],\n",
        "                             [96, 98, 100],\n",
        "                             [73, 66, 70]])\n",
        "# 정답값은 1사람당 1개\n",
        "y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"
      ],
      "metadata": {
        "id": "0rZlWuztHyj_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X 데이터셋과 Y 데이터 셋을 포장함함\n",
        "dataset = TensorDataset(x_train, y_train)\n",
        "print(list(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2X2x3wXI6NN",
        "outputId": "64013f79-7a47-404b-e90d-eae94635a914"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(tensor([93., 88., 93.], device='cuda:0'), tensor([185.])), (tensor([89., 91., 90.], device='cuda:0'), tensor([180.]))]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 개의 데이터를 1 세트로 만들어서 전체데이터셋을 쪼갠다. 이때 만든 n 개의 세트들의 순서를 shuffle 한다.\n",
        "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "U24caOCqI69z"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = nn.Sequential(\n",
        "          nn.Linear(3, 10, bias=True), # input_layer = 2, hidden_layer1 = 10\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3 = 10\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\n",
        "          nn.ReLU()\n",
        "          ).to(device)"
      ],
      "metadata": {
        "id": "SS-3I8-aKQiH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.MSELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) # 0.00001"
      ],
      "metadata": {
        "id": "WgWZab9kKSIB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nb_epochs = 5\n",
        "for epoch in range(nb_epochs + 1): #전체 데이터 셋으로 5번 학습할 것이다.\n",
        "  for batch_idx, samples in enumerate(dataloader): #minibatch 데이터를 반환하면서 index도 반환한다. GPU 터질까봐 mini batch 한다.\n",
        "\n",
        "    x_train, y_train = samples\n",
        "    x_train= x_train.to(device)\n",
        "    y_train= y_train.to(y_train)\n",
        "\n",
        "    # H(x) 계산\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # cost 계산\n",
        "    cost = criterion(prediction, y_train)\n",
        "\n",
        "    # cost로 H(x) 계산\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
        "        cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "lvj39GTJKTM5",
        "outputId": "d1685245-637b-49b0-dd15-fe8683a72593"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-367d33192d5f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# cost 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# cost로 H(x) 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3295\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_2 = torch.FloatTensor([[100, 70, 60], [150, 30,75]]).to(device)\n",
        "hypothesis = model(X_2)\n",
        "print(hypothesis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyIhjxnuMn4g",
        "outputId": "43ac11ce-6a60-4035-9707-9f9b233e99ed"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.9190],\n",
            "        [2.4369]], device='cuda:0', grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **CNN**"
      ],
      "metadata": {
        "id": "OsQyMUIdSagb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.init"
      ],
      "metadata": {
        "id": "PxQF9NFiSfxg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# 랜덤 시드 고정\n",
        "torch.manual_seed(777)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU3dPZKbSjcA",
        "outputId": "305cb668-7b50-435d-c2b7-f638e4f51886"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f13bc056990>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001 # 옵티마이저의 learning rate\n",
        "training_epochs = 15 # 학습횟수\n",
        "batch_size = 100 # minibatch 사이즈, 전체 데이터셋에서 서브 셋을 몇개로 묶을거냐"
      ],
      "metadata": {
        "id": "BlysPpWGSlNG"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
        "                          train=True, # True를 지정하면 훈련 데이터로 다운로드\n",
        "                          transform=transforms.ToTensor(), # 텐서로 변환, 토치에서 알아듣는 타입으로 지정\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
        "                         train=False, # False를 지정하면 테스트 데이터로 다운로드\n",
        "                         transform=transforms.ToTensor(), # 텐서로 변환, 토치에서 알아듣는 타입으로 지정\n",
        "                         download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzlrgUuNS3bO",
        "outputId": "7628c534-51b9-4a71-c7be-6008b62937a7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 106943590.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 96522465.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 26681885.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3149368.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True) #drop_last 마지막 남은 데이터를 버릴거냐 안버릴거냐"
      ],
      "metadata": {
        "id": "JECsCv22TXWS"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.nn.Module:  PyTorch의 모든 Neural Network의 Base Class\n",
        "class CNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # 첫번째층\n",
        "        # ImgIn shape=(?, 28, 28, 1)\n",
        "        #    Conv     -> (?, 28, 28, 32)\n",
        "        #    Pool     -> (?, 14, 14, 32)\n",
        "        self.layer1 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 두번째층\n",
        "        # ImgIn shape=(?, 14, 14, 32)\n",
        "        #    Conv      ->(?, 14, 14, 64)\n",
        "        #    Pool      ->(?, 7, 7, 64) \n",
        "        self.layer2 = torch.nn.Sequential(\n",
        "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "\n",
        "        # 전결합층 7x7x64 inputs -> 10 outputs\n",
        "        self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n",
        "\n",
        "        # 전결합층 한정으로 가중치 초기화\n",
        "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)   # 전결합층을 위해서 Flatten\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "miQQqdxdTiJ4"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN 모델 정의\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "WLMG8Wj6WwRX"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "1o7EGp9lWyGV"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_batch = len(data_loader)\n",
        "print('총 배치의 수 : {}'.format(total_batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmEIIV3pWzMh",
        "outputId": "805982e8-c215-412c-827a-c3122eb0e48f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "총 배치의 수 : 600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X, Y in data_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.\n",
        "        # image is already size of (28x28), no reshape\n",
        "\n",
        "        X = X.to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bTv1nvDYJja",
        "outputId": "4cfa017d-4762-4005-da38-9c59e1f949e9"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch:    1] cost = 0.225620762\n",
            "[Epoch:    2] cost = 0.0630199909\n",
            "[Epoch:    3] cost = 0.046338141\n",
            "[Epoch:    4] cost = 0.0374934077\n",
            "[Epoch:    5] cost = 0.0314498097\n",
            "[Epoch:    6] cost = 0.0261448771\n",
            "[Epoch:    7] cost = 0.0217737667\n",
            "[Epoch:    8] cost = 0.0182365105\n",
            "[Epoch:    9] cost = 0.016359888\n",
            "[Epoch:   10] cost = 0.0133685488\n",
            "[Epoch:   11] cost = 0.0101897297\n",
            "[Epoch:   12] cost = 0.0101049282\n",
            "[Epoch:   13] cost = 0.00833414495\n",
            "[Epoch:   14] cost = 0.00644074427\n",
            "[Epoch:   15] cost = 0.00643952331\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습을 진행하지 않을 것이므로 torch.no_grad(), gradient descent를 하지마라고 명령내리는 것\n",
        "with torch.no_grad():\n",
        "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = model(X_test)\n",
        "                        # CNN은 10개의 아웃풋으로 각 10개의 클래스에 대한 피처값이 나온다, 이를 axis 1방향으로 max값을 찾는다는 것\n",
        "                        # 이를 axis 1방향으로 max 값을 찾는다는것\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test # test는 숫자 정답값\n",
        "                        #torch.argmax(prediction, 1) 는 피쳐값을 max인 인덱스(index1)을 뽑는것\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iWKKSKkYNyd",
        "outputId": "6839e780-ab12-4fb0-96d1-29d8891fbbb2"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9878000020980835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장 \n",
        "torch.save(model.state_dict(),\"cnn_model.pt\")"
      ],
      "metadata": {
        "id": "6X5mnRu-YO3Q"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3-1 다시불러와서 추론 해보기기**"
      ],
      "metadata": {
        "id": "m3Q16s_XsJdk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 다시불러와서 추론 해보기\n",
        "model = CNN().to(device)\n",
        "model.load_state_dict(torch.load(\"cnn_model.pt\")) \n",
        "model.eval() #평가 모드로 설정하여야 합니다. 이 과정을 거치지 않으면 일관성 없는 추론 결과가 출력"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5JOEsm0sNBu",
        "outputId": "61acc898-6fdc-4c3b-cf96-81ffde23bd8c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (layer1): Sequential(\n",
              "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=3136, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습을 진행하지 않을 것이므로 torch.no_grad(), gradient descent를 하지마라고 명령내리는 것\n",
        "with torch.no_grad():\n",
        "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "  \n",
        "    prediction = model(X_test)\n",
        "                        # CNN은 10개의 아웃풋으로 각 10개의 클래스에 대한 피처값이 나온다, 이를 axis 1방향으로 max값을 찾는다는 것\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_kJTX6pbtA_0",
        "outputId": "056aaea4-61bc-4a6c-cad0-8e9be5f9ca8c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9878000020980835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습을 진행하지 않을 것이므로 torch.no_grad(), gradient descent를 하지마라고 명령내리는 것\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    # 이미지 파일 경로 설정\n",
        "    img = Image.open(\"./8.png\")\n",
        "    transform = transforms.Compose([\n",
        "          transforms.Grayscale(num_output_channels=1), # RGB(3D) -> Gray(2D)\n",
        "          transforms.Resize((28, 28)), # 모델 인풋에 맞게\n",
        "          transforms.ToTensor(), # 토치 텐서 타입으로 맞춰줘야함\n",
        "      ])\n",
        "    \n",
        "    img_tensor = transform(img).to(device) # [1, 28, 28]\n",
        "    img_tensor = img_tensor.unsqueeze(0) # [1, 1, 28, 28]\n",
        "\n",
        "    print(img_tensor.shape)\n",
        "\n",
        "    prediction = model(img_tensor)\n",
        "                        # CNN은 10개의 아웃풋으로 각 10개의 클래스에 대한 피처값이 나온다, 이를 axis 1방향으로 max값을 찾는다는 것 \n",
        "    print('result:', torch.argmax(prediction, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcgj1IzxtLbX",
        "outputId": "e853fad4-de2c-4d95-a1fe-bd70b31223e1"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 28, 28])\n",
            "result: tensor([8], device='cuda:0')\n"
          ]
        }
      ]
    }
  ]
}